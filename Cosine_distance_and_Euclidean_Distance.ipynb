{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPfKkp8GldCdYm/723+p4/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oasquared/DDDS-Cohort-16-Projects/blob/main/Cosine_distance_and_Euclidean_Distance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expected Result from the Analysis\n",
        "- Cosine distance between doc1 and doc3 would be very small (high similarity) since they have the same term distribution.\n",
        "\n",
        "- Cosine between doc1 and doc2 would be larger due to different word usage.\n",
        "\n",
        "- Euclidean distance between doc1 and doc3 will be large because doc3 has twice the magnitude (even though it's a repetition).\n",
        "\n",
        "- May incorrectly judge doc1 and doc3 as dissimilar due to magnitude difference.\n",
        "\n",
        "## Outcome  after coding\n",
        "\n",
        "- Doc1 and Doc3 are similar for both and eqaul distance.\n",
        "\n",
        "## Reading\n",
        "| Metric    | Sensitive to Length? | Common for Text? | Better for TF-IDF? |\n",
        "| --------- | -------------------- | ---------------- | ------------------ |\n",
        "| Cosine    | No                 | Yes            | Yes              |\n",
        "| Euclidean | Yes                | No             | No               |"
      ],
      "metadata": {
        "id": "06qmWGEhOQUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "7VknAflWO1bW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iaDfETyC3gl",
        "outputId": "ffa6123f-d7fc-4e0e-d2e2-5ac0011908bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Distance Matrix:\n",
            "          doc1      doc2      doc3\n",
            "doc1  0.000000  0.895521  0.000000\n",
            "doc2  0.895521  0.000000  0.895521\n",
            "doc3  0.000000  0.895521  0.000000\n",
            "\n",
            "Euclidean Distance Matrix:\n",
            "          doc1      doc2      doc3\n",
            "doc1  0.000000  1.338298  0.000000\n",
            "doc2  1.338298  0.000000  1.338298\n",
            "doc3  0.000000  1.338298  0.000000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
        "\n",
        "# Define documents\n",
        "doc1 = \"Mary had a little lamb\"\n",
        "doc2 = \"Say hello to my little friend\"\n",
        "doc3 = f\"{doc1} \" * 2  # Repetition of doc1 to increase length\n",
        "\n",
        "docs = [doc1, doc2, doc3]\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "# Compute distance matrices\n",
        "cosine_dist = cosine_distances(tfidf_matrix)\n",
        "euclid_dist = euclidean_distances(tfidf_matrix)\n",
        "\n",
        "# Display results\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Cosine Distance Matrix:\")\n",
        "print(pd.DataFrame(cosine_dist, index=[\"doc1\", \"doc2\", \"doc3\"], columns=[\"doc1\", \"doc2\", \"doc3\"]))\n",
        "\n",
        "print(\"\\nEuclidean Distance Matrix:\")\n",
        "print(pd.DataFrame(euclid_dist, index=[\"doc1\", \"doc2\", \"doc3\"], columns=[\"doc1\", \"doc2\", \"doc3\"]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VeSNxq3xJvJK",
        "outputId": "1716145e-5a3a-42b3-ba24-240fc136f96f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary had a little lamb Mary had a little lamb '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define documents\n",
        "doc1 = \"Mary had a little lamb\"\n",
        "doc2 = \"Say hello to my little friend\"\n",
        "doc3 = f\"{doc1} \" * 2  # Repetition to increase length\n",
        "\n",
        "docs = [doc1, doc2, doc3]\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "# Compute cosine similarity\n",
        "cos_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# Compute Euclidean distances and convert to similarity\n",
        "euc_dist = euclidean_distances(tfidf_matrix)\n",
        "euc_sim = 1 / (1 + euc_dist)  # Normalize to (0,1] range\n",
        "\n",
        "# Format and display\n",
        "labels = [\"doc1\", \"doc2\", \"doc3\"]\n",
        "cos_sim_df = pd.DataFrame(cos_sim, index=labels, columns=labels)\n",
        "euc_sim_df = pd.DataFrame(euc_sim, index=labels, columns=labels)\n",
        "\n",
        "print(\"Cosine Similarity Matrix:\")\n",
        "print(cos_sim_df)\n",
        "\n",
        "print(\"\\nEuclidean Similarity Matrix (1 / (1 + dist)):\")\n",
        "print(euc_sim_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAW7izQbJdtG",
        "outputId": "8881eafd-afa2-45e5-c25d-8adaf16ef348"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity Matrix:\n",
            "          doc1      doc2      doc3\n",
            "doc1  1.000000  0.104479  1.000000\n",
            "doc2  0.104479  1.000000  0.104479\n",
            "doc3  1.000000  0.104479  1.000000\n",
            "\n",
            "Euclidean Similarity Matrix (1 / (1 + dist)):\n",
            "          doc1      doc2      doc3\n",
            "doc1  1.000000  0.427661  1.000000\n",
            "doc2  0.427661  1.000000  0.427661\n",
            "doc3  1.000000  0.427661  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances, euclidean_distances\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Define the documents\n",
        "doc1 = \"Mary had a little lamb\"\n",
        "doc2 = \"Say hello to my little friend\"\n",
        "doc3 = f\"{doc1} \" * 2  # Longer version of doc1\n",
        "\n",
        "docs = [doc1, doc2, doc3]\n",
        "labels = [\"doc1\", \"doc2\", \"doc3\"]\n",
        "\n",
        "# Step 2: TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "# Step 3: Compute Distances\n",
        "cosine_dist = cosine_distances(tfidf_matrix)\n",
        "euclidean_dist = euclidean_distances(tfidf_matrix)\n",
        "\n",
        "# Step 4: Convert to Similarities\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)  # or 1 - cosine_dist\n",
        "euclidean_sim = 1 / (1 + euclidean_dist)      # custom similarity from distance\n",
        "\n",
        "# Step 5: Wrap results in DataFrames for readability\n",
        "def to_df(matrix, name):\n",
        "    return pd.DataFrame(matrix, index=labels, columns=labels).round(3).rename_axis(name)\n",
        "\n",
        "# Step 6: Print everything\n",
        "print(\"=== Cosine Similarity ===\")\n",
        "print(to_df(cosine_sim, \"Cosine Sim\"))\n",
        "\n",
        "print(\"\\n=== Cosine Distance ===\")\n",
        "print(to_df(cosine_dist, \"Cosine Dist\"))\n",
        "\n",
        "print(\"\\n=== Euclidean Distance ===\")\n",
        "print(to_df(euclidean_dist, \"Euclidean Dist\"))\n",
        "\n",
        "print(\"\\n=== Euclidean Similarity (1 / (1 + distance)) ===\")\n",
        "print(to_df(euclidean_sim, \"Euclidean Sim\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3w7ysAWKraI",
        "outputId": "b01a21d8-1bb2-421f-f50f-19e0750be780"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Cosine Similarity ===\n",
            "             doc1   doc2   doc3\n",
            "Cosine Sim                     \n",
            "doc1        1.000  0.104  1.000\n",
            "doc2        0.104  1.000  0.104\n",
            "doc3        1.000  0.104  1.000\n",
            "\n",
            "=== Cosine Distance ===\n",
            "              doc1   doc2   doc3\n",
            "Cosine Dist                     \n",
            "doc1         0.000  0.896  0.000\n",
            "doc2         0.896  0.000  0.896\n",
            "doc3         0.000  0.896  0.000\n",
            "\n",
            "=== Euclidean Distance ===\n",
            "                 doc1   doc2   doc3\n",
            "Euclidean Dist                     \n",
            "doc1            0.000  1.338  0.000\n",
            "doc2            1.338  0.000  1.338\n",
            "doc3            0.000  1.338  0.000\n",
            "\n",
            "=== Euclidean Similarity (1 / (1 + distance)) ===\n",
            "                doc1   doc2   doc3\n",
            "Euclidean Sim                     \n",
            "doc1           1.000  0.428  1.000\n",
            "doc2           0.428  1.000  0.428\n",
            "doc3           1.000  0.428  1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances, euclidean_distances\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Define the documents\n",
        "doc1 = \"Mary had a little lamb\"\n",
        "doc2 = \"Say hello to my little friend\"\n",
        "doc3 = (\"Mary had a little lamb \" * 2).strip()  # Longer version of doc1\n",
        "\n",
        "docs = [doc1, doc2, doc3]\n",
        "labels = [\"doc1\", \"doc2\", \"doc3\"]\n",
        "\n",
        "# Step 2: TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "# Step 3: Compute distance and similarity matrices\n",
        "cos_sim = cosine_similarity(tfidf_matrix)\n",
        "cos_dist = cosine_distances(tfidf_matrix)\n",
        "euc_dist = euclidean_distances(tfidf_matrix)\n",
        "euc_sim = 1 / (1 + euc_dist)\n",
        "\n",
        "# Step 4: Create combined table\n",
        "pairs = []\n",
        "for i in range(len(docs)):\n",
        "    for j in range(i, len(docs)):  # Avoid duplicates\n",
        "        pairs.append({\n",
        "            \"Pair\": f\"{labels[i]}-{labels[j]}\",\n",
        "            \"Cosine Similarity\": round(cos_sim[i, j], 3),\n",
        "            \"Cosine Distance\": round(cos_dist[i, j], 3),\n",
        "            \"Euclidean Distance\": round(euc_dist[i, j], 3),\n",
        "            \"Euclidean Similarity\": round(euc_sim[i, j], 3)\n",
        "        })\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "combined_df = pd.DataFrame(pairs)\n",
        "print(\"\\n=== Combined Distance & Similarity Table ===\")\n",
        "print(combined_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jJJjsW1LieW",
        "outputId": "b403dd6c-faa7-4c4e-e1db-187a5de9a39f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Combined Distance & Similarity Table ===\n",
            "     Pair  Cosine Similarity  Cosine Distance  Euclidean Distance  Euclidean Similarity\n",
            "doc1-doc1              1.000            0.000               0.000                 1.000\n",
            "doc1-doc2              0.104            0.896               1.338                 0.428\n",
            "doc1-doc3              1.000            0.000               0.000                 1.000\n",
            "doc2-doc2              1.000            0.000               0.000                 1.000\n",
            "doc2-doc3              0.104            0.896               1.338                 0.428\n",
            "doc3-doc3              1.000            0.000               0.000                 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances, euclidean_distances\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Define the documents\n",
        "doc1 = \"Mary had a little lamb\"\n",
        "doc2 = \"Say hello to my little friend\"\n",
        "doc3 = (\"Mary had a little lamb \" * 2).strip()  # Clean repeat of doc1\n",
        "\n",
        "docs = [doc1, doc2, doc3]\n",
        "labels = [\"doc1\", \"doc2\", \"doc3\"]\n",
        "\n",
        "# Step 2: TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "# Step 3: Compute similarity and distance matrices\n",
        "cos_sim = cosine_similarity(tfidf_matrix)\n",
        "cos_dist = cosine_distances(tfidf_matrix)\n",
        "euc_dist = euclidean_distances(tfidf_matrix)\n",
        "euc_sim = 1 / (1 + euc_dist)\n",
        "\n",
        "# Step 4: Prepare combined table with exact pairs and rounding\n",
        "pairs = []\n",
        "for i in range(len(docs)):\n",
        "    for j in range(i, len(docs)):  # Include self-pairs only once\n",
        "        pairs.append({\n",
        "            \"Pair\": f\"{labels[i]}-{labels[j]}\",\n",
        "            \"Cosine Similarity\": round(cos_sim[i, j], 3),\n",
        "            \"Cosine Distance\": round(cos_dist[i, j], 3),\n",
        "            \"Euclidean Distance\": round(euc_dist[i, j], 3),\n",
        "            \"Euclidean Similarity\": round(euc_sim[i, j], 3)\n",
        "        })\n",
        "\n",
        "# Step 5: Create and print the final DataFrame\n",
        "combined_df = pd.DataFrame(pairs)\n",
        "print(\"\\n=== Combined Distance & Similarity Table ===\")\n",
        "print(combined_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIISUEEuM0Y8",
        "outputId": "40bb290d-fa3a-4a90-aff3-60691ba6bdb6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Combined Distance & Similarity Table ===\n",
            "     Pair  Cosine Similarity  Cosine Distance  Euclidean Distance  Euclidean Similarity\n",
            "doc1-doc1              1.000            0.000               0.000                 1.000\n",
            "doc1-doc2              0.104            0.896               1.338                 0.428\n",
            "doc1-doc3              1.000            0.000               0.000                 1.000\n",
            "doc2-doc2              1.000            0.000               0.000                 1.000\n",
            "doc2-doc3              0.104            0.896               1.338                 0.428\n",
            "doc3-doc3              1.000            0.000               0.000                 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pandas as pd\n",
        "\n",
        "# Define documents\n",
        "doc1 = \"Mary had a little lamb\"\n",
        "doc2 = \"Say hello to my little friend\"\n",
        "doc3 = (\"Mary had a little lamb \" * 2).strip()  # Clean repeated doc1\n",
        "docs = [doc1, doc2, doc3]\n",
        "labels = [\"doc1\", \"doc2\", \"doc3\"]\n",
        "\n",
        "# Vectorize using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "# Helper function to run KNN with given metric\n",
        "def run_knn(metric_name, metric):\n",
        "    knn = NearestNeighbors(n_neighbors=3, metric=metric)\n",
        "    knn.fit(tfidf_matrix)\n",
        "    distances, indices = knn.kneighbors(tfidf_matrix)\n",
        "\n",
        "    # Collect results\n",
        "    result = []\n",
        "    for i, (dists, nbrs) in enumerate(zip(distances, indices)):\n",
        "        for dist, nbr in zip(dists, nbrs):\n",
        "            result.append({\n",
        "                \"Doc\": labels[i],\n",
        "                \"Neighbor\": labels[nbr],\n",
        "                f\"{metric_name} Distance\": round(dist, 3)\n",
        "            })\n",
        "    return pd.DataFrame(result)\n",
        "\n",
        "# Run KNN using Cosine and Euclidean\n",
        "cosine_results = run_knn(\"Cosine\", \"cosine\")\n",
        "euclidean_results = run_knn(\"Euclidean\", \"euclidean\")\n",
        "\n",
        "# Display results\n",
        "print(\"=== KNN with Cosine Distance ===\")\n",
        "print(cosine_results.to_string(index=False))\n",
        "\n",
        "print(\"\\n=== KNN with Euclidean Distance ===\")\n",
        "print(euclidean_results.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA4ONhioNXtg",
        "outputId": "a719b096-d6b7-4c53-b22c-92bb9b17055e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== KNN with Cosine Distance ===\n",
            " Doc Neighbor  Cosine Distance\n",
            "doc1     doc1            0.000\n",
            "doc1     doc3            0.000\n",
            "doc1     doc2            0.896\n",
            "doc2     doc2            0.000\n",
            "doc2     doc1            0.896\n",
            "doc2     doc3            0.896\n",
            "doc3     doc1            0.000\n",
            "doc3     doc3            0.000\n",
            "doc3     doc2            0.896\n",
            "\n",
            "=== KNN with Euclidean Distance ===\n",
            " Doc Neighbor  Euclidean Distance\n",
            "doc1     doc1               0.000\n",
            "doc1     doc3               0.000\n",
            "doc1     doc2               1.338\n",
            "doc2     doc2               0.000\n",
            "doc2     doc1               1.338\n",
            "doc2     doc3               1.338\n",
            "doc3     doc1               0.000\n",
            "doc3     doc3               0.000\n",
            "doc3     doc2               1.338\n"
          ]
        }
      ]
    }
  ]
}